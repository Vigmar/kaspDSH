# -*- coding: utf-8 -*-
"""Privacy.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Cr8f34_TbHMufDXAaH-DIKb82A6bb6xl
"""

#!unzip -q /content/dataset_PrivacyMap.zip

import nltk
from nltk import ne_chunk, pos_tag, word_tokenize
from nltk.tree import Tree

nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')
nltk.download('maxent_ne_chunker')
nltk.download('words')

import json
import yaml
from tqdm import tqdm

policies = {}

for i in tqdm(range(1, 351)):
  path = 'data/annotations/policy_{}.yml'.format(i)
  with open(path) as file:
    policy = yaml.load(file)
  policies[policy['policy_name']] = policy

companies = set(policies.keys())

len(companies)

def extract_companies_from_segment(segment, companies):
  text_merged = ''.join(segment.split())
  extracted = []
  for company in companies:
    if company in text_merged:
      extracted.append(company)
  return extracted

def parse_policy_annotations(policy, companies):
  FIRST_PARTY_SUFFIX = '_1stParty'
  THIRD_PARTY_SUFFIX = '_3rdParty'

  parsed = {
      'company': policy['policy_name'],
      'collects': {},
      'transfers': {}
  }
  for segment in policy['segments']:
    for annotation in segment['annotations']:
      sends_to = set(extract_companies_from_segment(segment['segment_text'], companies))
      if annotation['modality'] == 'PERFORMED':
        practice = annotation['practice']
        if practice.endswith(FIRST_PARTY_SUFFIX):
          practice = practice[:-len(FIRST_PARTY_SUFFIX)]
          if practice not in parsed['collects']:
            parsed['collects'][practice] = set()
          parsed['collects'][practice] |= sends_to
        elif practice.endswith(THIRD_PARTY_SUFFIX):
          if not sends_to:
            continue
          practice = practice[:-len(THIRD_PARTY_SUFFIX)]
          if practice not in parsed['transfers']:
            parsed['transfers'][practice] = set()
          parsed['transfers'][practice] |= sends_to
        elif practice.endswith('SSO'):
          continue
        else:
          print('Unknown practice suffix: {}'.format(practice))
  return parsed

parsed_policies = {}
for name, policy in tqdm(policies.items()):
  parsed_policies[name] = parse_policy_annotations(policy, companies)

policies['Scan']

non_empty_nodes = set() 
nodes = []
links_set = set()
for _, pp in parsed_policies.items():
  company = pp['company']
  nodes.append({'id': company})
  for _, companies in pp['collects'].items():
    for src in companies:
      if src == company:
        continue
      non_empty_nodes.add(src)
      non_empty_nodes.add(company)
      links_set.add((src, company))
  for _, companies in pp['transfers'].items():
    for dst in companies:
      if dst == company:
        continue
      non_empty_nodes.add(dst)
      non_empty_nodes.add(company)
      links_set.add((company, dst))

data = {
    'nodes': [n for n in nodes if n['id'] in non_empty_nodes],
    'links': [{'source': l[0], 'target': l[1]} for l in links_set if l[0] != l[1]]
}
with open('graph.json', 'w') as file:
  json.dump(data, file)